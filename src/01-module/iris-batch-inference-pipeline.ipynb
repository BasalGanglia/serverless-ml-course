{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2kLrOh-bpGy"
   },
   "source": [
    "# Iris Flower - Batch Prediction\n",
    "\n",
    "\n",
    "In this notebook we will, \n",
    "\n",
    "1. Load the batch inference data that arrived in the last 24 hours\n",
    "2. Predict the first Iris Flower found in the batch\n",
    "3. Write the ouput png of the Iris flower predicted, to be displayed in Github Pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "xRtpj-psbpG8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/285\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import hopsworks\n",
    "import joblib\n",
    "\n",
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Downloading file ... "
     ]
    }
   ],
   "source": [
    "mr = project.get_model_registry()\n",
    "model = mr.get_model(\"iris\", version=1)\n",
    "model_dir = model.download()\n",
    "model = joblib.load(model_dir + \"/iris_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are downloading the 'raw' iris data. We explicitly do not want transformed data, reading for training. \n",
    "\n",
    "So, let's download the iris dataset, and preview some rows. \n",
    "\n",
    "Note, that it is 'tabular data'. There are 5 columns: 4 of them are \"features\", and the \"variety\" column is the **target** (what we are trying to predict using the 4 feature values in the target's row)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "nRmFM7vcbpHA",
    "outputId": "d920d168-9818-40c5-c292-4cf0afcbbcfd"
   },
   "outputs": [],
   "source": [
    "feature_view = fs.get_feature_view(name=\"iris\", version=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will do some **Batch Inference**. \n",
    "\n",
    "We will read all the input features that have arrived in the last 24 hours, and score them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "uHuAD3ttP8Ep"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VersionWarning: No training dataset version was provided to initialise batch scoring . Defaulting to version 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-02 19:31:41,666 INFO: USE `ilkkakos_featurestore`\n",
      "2022-10-02 19:31:42,646 INFO: SELECT `fg0`.`sepal_length` `sepal_length`, `fg0`.`sepal_width` `sepal_width`, `fg0`.`petal_length` `petal_length`, `fg0`.`petal_width` `petal_width`\n",
      "FROM `ilkkakos_featurestore`.`iris_1` `fg0`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Versicolor', 'Setosa', 'Versicolor', 'Versicolor', 'Virginica',\n",
       "       'Setosa', 'Virginica', 'Versicolor', 'Versicolor', 'Versicolor',\n",
       "       'Virginica', 'Virginica', 'Virginica', 'Virginica', 'Virginica',\n",
       "       'Virginica', 'Versicolor', 'Setosa', 'Versicolor', 'Versicolor',\n",
       "       'Versicolor', 'Versicolor', 'Versicolor', 'Setosa', 'Virginica',\n",
       "       'Setosa', 'Setosa', 'Versicolor', 'Setosa', 'Setosa', 'Virginica',\n",
       "       'Versicolor', 'Virginica', 'Virginica', 'Setosa', 'Setosa',\n",
       "       'Virginica', 'Setosa', 'Versicolor', 'Setosa', 'Virginica',\n",
       "       'Versicolor', 'Versicolor', 'Setosa', 'Versicolor', 'Versicolor',\n",
       "       'Virginica', 'Versicolor', 'Versicolor', 'Versicolor',\n",
       "       'Versicolor', 'Virginica', 'Versicolor', 'Virginica', 'Versicolor',\n",
       "       'Setosa', 'Versicolor', 'Virginica', 'Setosa', 'Setosa', 'Setosa',\n",
       "       'Virginica', 'Setosa', 'Setosa', 'Versicolor', 'Versicolor',\n",
       "       'Virginica', 'Versicolor', 'Versicolor', 'Virginica', 'Versicolor',\n",
       "       'Versicolor', 'Setosa', 'Versicolor', 'Virginica', 'Virginica',\n",
       "       'Versicolor', 'Virginica', 'Virginica', 'Virginica', 'Versicolor',\n",
       "       'Virginica', 'Versicolor', 'Virginica', 'Virginica', 'Setosa',\n",
       "       'Versicolor', 'Virginica', 'Versicolor', 'Setosa', 'Versicolor',\n",
       "       'Versicolor', 'Virginica', 'Setosa', 'Setosa', 'Setosa',\n",
       "       'Versicolor', 'Virginica', 'Setosa', 'Virginica', 'Setosa',\n",
       "       'Setosa', 'Versicolor', 'Virginica', 'Setosa', 'Versicolor',\n",
       "       'Setosa', 'Setosa', 'Setosa', 'Virginica', 'Setosa', 'Virginica',\n",
       "       'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa',\n",
       "       'Versicolor', 'Setosa', 'Setosa', 'Setosa', 'Versicolor',\n",
       "       'Virginica', 'Versicolor', 'Setosa', 'Virginica', 'Setosa',\n",
       "       'Versicolor', 'Setosa', 'Setosa', 'Virginica', 'Virginica',\n",
       "       'Setosa', 'Versicolor', 'Setosa', 'Versicolor', 'Virginica',\n",
       "       'Virginica', 'Versicolor', 'Versicolor', 'Virginica', 'Versicolor',\n",
       "       'Virginica', 'Versicolor', 'Versicolor', 'Setosa', 'Versicolor',\n",
       "       'Setosa', 'Versicolor', 'Setosa', 'Versicolor', 'Virginica',\n",
       "       'Setosa', 'Virginica', 'Setosa'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "from PIL import Image\n",
    "\n",
    "batch_data = feature_view.get_batch_data()\n",
    "\n",
    "y_pred = model.predict(batch_data)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch prediction output is the last entry in the batch - it is output as a file 'latest_iris.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower = y_pred[y_pred.size-1]\n",
    "flower_img = \"assets/\" + flower + \".png\"\n",
    "img = Image.open(flower_img)            \n",
    "\n",
    "img.save(\"../../assets/latest_iris.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_fg = fs.get_feature_group(name=\"iris\", version=1)\n",
    "df = iris_fg.read()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = df.iloc[-1][\"variety\"]\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_flower = \"assets/\" + label + \".png\"\n",
    "\n",
    "img = Image.open(label_flower)            \n",
    "\n",
    "img.save(\"../../assets/actual_iris.png\",table_conversion = 'matplotlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "monitor_fg = fs.get_or_create_feature_group(name=\"iris_predictions\",\n",
    "                                  version=1,\n",
    "                                  primary_key=[\"datetime\"],\n",
    "                                  description=\"Iris flower Prediction/Outcome Monitoring\"\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "\n",
    "data = {\n",
    "    'prediction': [flower],\n",
    "    'label': [label],\n",
    "    'datetime': [now],\n",
    "}\n",
    "monitor_df = pd.DataFrame(data)\n",
    "monitor_fg.insert(monitor_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = monitor_fg.read()\n",
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataframe_image as dfi\n",
    "\n",
    "df_recent = history_df.tail(5)\n",
    " \n",
    "# If you exclude this image, you may have the same iris_latest.png and iris_actual.png files\n",
    "# If no files have changed, the GH-action 'git commit/push' stage fails, failing your GH action (last step)\n",
    "# This image, however, is always new, ensuring git commit/push will succeed.\n",
    "dfi.export(df_recent, '../../assets/df_recent.png', table_conversion = 'matplotlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predictions = history_df[['prediction']]\n",
    "labels = history_df[['label']]\n",
    "\n",
    "results = confusion_matrix(labels, predictions)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "\n",
    "# Only create the confusion matrix when our iris_predictions feature group has examples of all 3 iris flowers\n",
    "if results.shape == (3,3):\n",
    "\n",
    "    df_cm = pd.DataFrame(results, ['True Setosa', 'True Versicolor', 'True Virginica'],\n",
    "                         ['Pred Setosa', 'Pred Versicolor', 'Pred Virginica'])\n",
    "\n",
    "    cm = sns.heatmap(df_cm, annot=True)\n",
    "\n",
    "    fig = cm.get_figure()\n",
    "    fig.savefig(\"../../assets/confusion_matrix.png\") \n",
    "    df_cm\n",
    "else:\n",
    "    print(\"Run the batch inference pipeline more times until you get 3 different iris flowers\")    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
<<<<<<< HEAD
   "display_name": "Python 3.9.5 ('VENV': venv)",
=======
   "display_name": "Python 3.10.6 64-bit",
>>>>>>> f72c93a7f3d4a0bf643b2addb352f8ebd498b820
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "78183483f5a2460ffcdf55e781af792653e75c8e1be8465772f64bb4a5363d70"
=======
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
>>>>>>> f72c93a7f3d4a0bf643b2addb352f8ebd498b820
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
